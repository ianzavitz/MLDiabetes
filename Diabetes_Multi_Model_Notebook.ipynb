{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "'''\n",
    "def crossCheck(cross,foldnum):\n",
    "    scores=[]\n",
    "    for i in range(len(cross)):\n",
    "\n",
    "        ctrain=[]\n",
    "        ctrain_y=[]\n",
    "        testnum=foldnum-i-1\n",
    "        testme=[]\n",
    "        testme_y=[]\n",
    "        \n",
    "        testme=np.array(testme)\n",
    "        testme_y=np.array(testme_y)\n",
    "        j=0\n",
    "        while j<len(cross):\n",
    "\n",
    "            \n",
    "            if j!=testnum:\n",
    "                for thing in cross[j]:\n",
    "                    ctrain.append(thing[0])\n",
    "                    ctrain_y.append(thing[1])\n",
    "               \n",
    "            j+=1\n",
    "'''\n",
    "### FORMATTING DATA ###\n",
    "data=pd.read_csv('diabetic_data.csv')\n",
    "diag=data[['diag_1','diag_2','diag_3']]\n",
    "data=data.drop(['admission_type_id','discharge_disposition_id','admission_source_id','max_glu_serum','number_inpatient','number_emergency','number_outpatient','encounter_id','patient_nbr','weight','payer_code','A1Cresult','medical_specialty','max_glu_serum','diag_1','diag_2','diag_3'],axis=1)\n",
    "data=data.drop(data[data.race=='?'].index)\n",
    "data=data.drop(data[data.gender=='Unknown/Invalid'].index)\n",
    "read=data['readmitted']\n",
    "read=read.str.upper()\n",
    "read=read.replace(['NO','<30','>30'],[0,1,1])\n",
    "data=data.replace(['None','Female','No','Down'],0)\n",
    "data=data.replace(['Male','Yes','Up','Steady'],1)\n",
    "data=data.replace(['Down'],2)\n",
    "r=pd.get_dummies(data[['race','diabetesMed']])\n",
    "change=pd.get_dummies(data['change'])\n",
    "a=pd.get_dummies(data['age'])\n",
    "newdata=pd.concat([data,r,a,change],axis=1)\n",
    "newdata=newdata.drop(['age','race','readmitted','change','diabetesMed'],axis=1)\n",
    "X=data.drop(['readmitted'],axis=1)\n",
    "read=np.array(read)\n",
    "########################\n",
    "\n",
    "#### SPLITTING DATA ####\n",
    "x, X_test, y, y_test = train_test_split(newdata, read, test_size = 0.15, random_state = 0)\n",
    "X_train,x_dev,y_train,y_dev=train_test_split(x,y,test_size=.18, random_state=0)\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing newton-cg\n",
      "  C= 0.0001 : Accuracy: 0.55843 Precision: 0.54594 Recall: 0.36833 F1: 0.43988\n",
      "  C= 0.001 : Accuracy: 0.55567 Precision: 0.54578 Recall: 0.40341 F1: 0.46392\n",
      "  C= 0.01 : Accuracy: 0.55837 Precision: 0.54649 Recall: 0.40674 F1: 0.46637\n",
      "  C= 0.1 : Accuracy: 0.55909 Precision: 0.54596 Recall: 0.40854 F1: 0.46736\n",
      "  C= 1 : Accuracy: 0.55889 Precision: 0.54561 Recall: 0.40813 F1: 0.46696\n",
      "  C= 10 : Accuracy: 0.55863 Precision: 0.5453 Recall: 0.40813 F1: 0.46685\n",
      "  C= 20 : Accuracy: 0.55843 Precision: 0.5454 Recall: 0.40813 F1: 0.46688\n",
      "  C= 50 : Accuracy: 0.5585 Precision: 0.5454 Recall: 0.40813 F1: 0.46688\n",
      "  C= 100 : Accuracy: 0.5585 Precision: 0.5454 Recall: 0.40813 F1: 0.46688\n",
      "  C= 1000 : Accuracy: 0.5585 Precision: 0.5454 Recall: 0.40813 F1: 0.46688\n",
      "Testing lbfgs\n",
      "  C= 0.0001 : Accuracy: 0.5585 Precision: 0.54545 Recall: 0.3686 F1: 0.43992\n",
      "  C= 0.001 : Accuracy: 0.55541 Precision: 0.548 Recall: 0.40771 F1: 0.46756\n",
      "  C= 0.01 : Accuracy: 0.56014 Precision: 0.5457 Recall: 0.41312 F1: 0.47024\n",
      "  C= 0.1 : Accuracy: 0.55909 Precision: 0.54742 Recall: 0.41867 F1: 0.47446\n",
      "  C= 1 : Accuracy: 0.56066 Precision: 0.54738 Recall: 0.40771 F1: 0.46733\n",
      "  C= 10 : Accuracy: 0.55975 Precision: 0.54616 Recall: 0.40771 F1: 0.46689\n",
      "  C= 20 : Accuracy: 0.55896 Precision: 0.54761 Recall: 0.39634 F1: 0.45986\n",
      "  C= 50 : Accuracy: 0.55896 Precision: 0.54645 Recall: 0.40868 F1: 0.46763\n",
      "  C= 100 : Accuracy: 0.55922 Precision: 0.54459 Recall: 0.41159 F1: 0.46884\n",
      "  C= 1000 : Accuracy: 0.55823 Precision: 0.54457 Recall: 0.41256 F1: 0.46947\n",
      "Testing liblinear\n",
      "  C= 0.0001 : Accuracy: 0.5583 Precision: 0.55266 Recall: 0.27943 F1: 0.37119\n",
      "  C= 0.001 : Accuracy: 0.55153 Precision: 0.5496 Recall: 0.36569 F1: 0.43917\n",
      "  C= 0.01 : Accuracy: 0.55758 Precision: 0.54913 Recall: 0.40147 F1: 0.46383\n",
      "  C= 0.1 : Accuracy: 0.56034 Precision: 0.54694 Recall: 0.40799 F1: 0.46736\n",
      "  C= 1 : Accuracy: 0.55948 Precision: 0.54599 Recall: 0.40827 F1: 0.46719\n",
      "  C= 10 : Accuracy: 0.55889 Precision: 0.54561 Recall: 0.40813 F1: 0.46696\n",
      "  C= 20 : Accuracy: 0.55863 Precision: 0.54579 Recall: 0.40827 F1: 0.46712\n",
      "  C= 50 : Accuracy: 0.55876 Precision: 0.54581 Recall: 0.40813 F1: 0.46703\n",
      "  C= 100 : Accuracy: 0.55876 Precision: 0.54567 Recall: 0.4084 F1: 0.46716\n",
      "  C= 1000 : Accuracy: 0.55869 Precision: 0.54547 Recall: 0.4084 F1: 0.46709\n",
      "Testing sag\n",
      "  C= 0.0001 : Accuracy: 0.55856 Precision: 0.54594 Recall: 0.36833 F1: 0.43988\n",
      "  C= 0.001 : Accuracy: 0.55567 Precision: 0.54578 Recall: 0.40341 F1: 0.46392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C= 0.01 : Accuracy: 0.55837 Precision: 0.54728 Recall: 0.40535 F1: 0.46574\n",
      "  C= 0.1 : Accuracy: 0.55948 Precision: 0.54667 Recall: 0.40854 F1: 0.46762\n",
      "  C= 1 : Accuracy: 0.55935 Precision: 0.54679 Recall: 0.40924 F1: 0.46812\n",
      "  C= 10 : Accuracy: 0.55948 Precision: 0.54658 Recall: 0.40924 F1: 0.46804\n",
      "  C= 20 : Accuracy: 0.55935 Precision: 0.5467 Recall: 0.4091 F1: 0.46799\n",
      "  C= 50 : Accuracy: 0.55942 Precision: 0.54679 Recall: 0.40924 F1: 0.46812\n",
      "  C= 100 : Accuracy: 0.55948 Precision: 0.54679 Recall: 0.40924 F1: 0.46812\n",
      "  C= 1000 : Accuracy: 0.55948 Precision: 0.5467 Recall: 0.4091 F1: 0.46799\n",
      "\n",
      "Best model score by accuracy: 0.560664783551 from LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Corresponding f1: 0.4744617318874745\n"
     ]
    }
   ],
   "source": [
    "#### Logistic Regression ####\n",
    "models = []\n",
    "sol=['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "cs=[.0001,.001,.01,.1,1,10,20,50,100,1000]\n",
    "for s in sol:\n",
    "    print(\"Testing\",s)\n",
    "    for c in cs:\n",
    "        model = LogisticRegression(C=c,solver=s)\n",
    "        model.fit(X_train,y_train)\n",
    "        pred=(model.predict(x_dev))\n",
    "        testy=np.array(y_dev)\n",
    "    \n",
    "        i=0\n",
    "        falsep=0\n",
    "        falsen=0\n",
    "        wrongn=0\n",
    "        rightp=0\n",
    "        for thing in pred:\n",
    "            if thing != testy[i] and thing==1:\n",
    "                falsep+=1\n",
    "            elif thing!=testy[i] and thing==0:\n",
    "                falsen+=1\n",
    "            elif thing==testy[i] and thing==1:\n",
    "                rightp+=1\n",
    "            else: \n",
    "                wrongn+=1\n",
    "\n",
    "\n",
    "            i+=1\n",
    "        p=rightp/(rightp+falsep)\n",
    "        r=rightp/(falsen+rightp)\n",
    "        f=2*((p*r)/(p+r))\n",
    "        print(\"  C =\",c,\": Accuracy:\",round(acc,5),\"Precision:\",round(p,5),\"Recall:\",round(r,5),\"F1:\",round(f,5))\n",
    "        #print(model.feature_importances_)\n",
    "        acc=accuracy_score(pred,testy)\n",
    "        models.append((model,acc,f))\n",
    "        \n",
    "top_acc = max(models,key=itemgetter(1))[1]\n",
    "top_acc_f1 = max(models,key=itemgetter(1))[2]\n",
    "top_model_acc = max(models,key=itemgetter(1))[0]\n",
    "\n",
    "print('\\nBest model score by accuracy:',top_acc,\"\\nfrom model:  \",top_model_acc)\n",
    "print('\\nCorresponding f1:',top_acc_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.567496551271\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.574065558694\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.570321224463\n",
      "10 estimators \tbest at max_depth = 10 \n",
      "score = 0.574065558694\n",
      "\n",
      "\n",
      "n_estimators = 15\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.560927543848\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.572423306838\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.573145897655\n",
      "15 estimators \tbest at max_depth = 15 \n",
      "score = 0.573145897655\n",
      "\n",
      "\n",
      "n_estimators = 20\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.561912894962\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.576364711292\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.572686067135\n",
      "20 estimators \tbest at max_depth = 10 \n",
      "score = 0.576364711292\n",
      "\n",
      "\n",
      "\n",
      "final test score: 0.562784776199\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117155438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gender   2 time_in_hospital   3 num_lab_procedures   4 num_procedures   5 num_medications   6 number_diagnoses   7 metformin   8 repaglinide   9 nateglinide   10 chlorpropamide   11 glimepiride   12 acetohexamide   13 glipizide   14 glyburide   15 tolbutamide   16 pioglitazone   17 rosiglitazone   18 acarbose   19 miglitol   20 troglitazone   21 tolazamide   22 examide   23 citoglipton   24 insulin   25 glyburide-metformin   26 glipizide-metformin   27 glimepiride-pioglitazone   28 metformin-rosiglitazone   29 metformin-pioglitazone   30 race_AfricanAmerican   31 race_Asian   32 race_Caucasian   33 race_Hispanic   34 race_Other   35 [0-10)   36 [10-20)   37 [20-30)   38 [30-40)   39 [40-50)   40 [50-60)   41 [60-70)   42 [70-80)   43 [80-90)   44 [90-100)   45 0   46 Ch   "
     ]
    }
   ],
   "source": [
    "#### RANDOM FOREST ####\n",
    "\n",
    "\n",
    "#hyperparameter grid search \n",
    "mxDepth = [5,10,15] #mxDepth \n",
    "n_ests = [10,15,20] #n_estimators\n",
    "best_models = []\n",
    "for n in n_ests:\n",
    "    print(\"n_estimators =\",n)\n",
    "    maximized_models=[]\n",
    "    for mD in mxDepth:\n",
    "        results = []\n",
    "        print(\"\\tmax_depth =\",mD)\n",
    "        for _ in range(51):\n",
    "            model = RandomForestClassifier(n_estimators=n,max_depth=mD)\n",
    "            model.fit(X_train,y_train)\n",
    "            pred = model.predict(x_dev)\n",
    "            testy=np.array(y_dev)\n",
    "            print('\\t'+str(_)+\" iterations\",end=\"\\r\",flush=True)\n",
    "\n",
    "            results.append((model,accuracy_score(pred,testy)))\n",
    "        print('\\n\\tBest model score:',max(results,key=itemgetter(1))[1])\n",
    "        maximized_models.append((max(results,key=itemgetter(1))[0],max(results,key=itemgetter(1))[1],mD))\n",
    "\n",
    "    print(n,\"estimators\",\"\\tbest at max_depth =\",max(maximized_models,key=itemgetter(1))[2],\"\\nscore =\",max(maximized_models,key=itemgetter(1))[1])\n",
    "    print(\"\\n\")\n",
    "    best_models.append((max(maximized_models,key=itemgetter(1))[0],max(maximized_models,key=itemgetter(1))[1],n))\n",
    "\n",
    "#grid search derived best model\n",
    "final_best = max(best_models,key=itemgetter(1))[0]\n",
    "\n",
    "#score\n",
    "pred_final = final_best.predict(X_test)\n",
    "print(\"\\nfinal test score:\",accuracy_score(pred_final,np.array(y_test)))\n",
    "\n",
    "plt.bar(range(1,len(final_best.feature_importances_)+1),final_best.feature_importances_,ls=\"None\")\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.ylabel(\"Importance (%)\")\n",
    "plt.title(\"Variable Importances\")\n",
    "plt.show()\n",
    "for idx, column in enumerate(newdata.columns):\n",
    "    print(idx+1, column, end=\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Caucasian' 0 '[40-50)' ..., 'Ch' 1 '>30']\n",
      " ['AfricanAmerican' 1 '[70-80)' ..., 'Ch' 1 'NO']\n",
      " ['Other' 1 '[60-70)' ..., 0 1 'NO']\n",
      " ..., \n",
      " ['Caucasian' 1 '[90-100)' ..., 0 1 'NO']\n",
      " ['Caucasian' 0 '[80-90)' ..., 'Ch' 1 'NO']\n",
      " ['Hispanic' 0 '[50-60)' ..., 'Ch' 1 'NO']]\n",
      "0.5408067542213884\n"
     ]
    }
   ],
   "source": [
    "#### Baye's ####\n",
    "\n",
    "#bayes doesn't work for the hold out method, so we won't have a dev set\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, read, test_size=0.3,random_state=0)\n",
    "#print(train_X)\n",
    "trainX=np.array(test_X)\n",
    "trainy=np.array(test_y)\n",
    "\n",
    "#print(trainX)\n",
    "answers=[]\n",
    "for thing in trainX:\n",
    "   # print(len(thing))\n",
    "    #num lab, diabetes meds, time in hospital <4\n",
    "    if thing[2]==1 and thing[3]>=4 and thing[4]>=40 and thing[31]=='Yes':\n",
    "       # print(thing[31])\n",
    "        answers.append(1)\n",
    "    else:\n",
    "        answers.append(0)\n",
    "i=0\n",
    "#trainX=list(trainX)\n",
    "test=0\n",
    "print(trainX)\n",
    "for answer in answers:\n",
    "    if answer==trainy[i]:\n",
    "        test+=1\n",
    "    i+=1\n",
    "print(test/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
