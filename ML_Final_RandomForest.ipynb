{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "def crossCheck(cross,foldnum):\n",
    "    scores=[]\n",
    "    for i in range(len(cross)):\n",
    "\n",
    "        ctrain=[]\n",
    "        ctrain_y=[]\n",
    "        testnum=foldnum-i-1\n",
    "        testme=[]\n",
    "        testme_y=[]\n",
    "        \n",
    "        testme=np.array(testme)\n",
    "        testme_y=np.array(testme_y)\n",
    "        j=0\n",
    "        while j<len(cross):\n",
    "\n",
    "            \n",
    "            if j!=testnum:\n",
    "                for thing in cross[j]:\n",
    "                    ctrain.append(thing[0])\n",
    "                    ctrain_y.append(thing[1])\n",
    "               \n",
    "            j+=1\n",
    "\n",
    "# meds=[]\n",
    "# with open('meds.txt') as medt:\n",
    "#     meds=medt.readline().strip().split('\\t')\n",
    "data=pd.read_csv('diabetic_data.csv')\n",
    "diag=data[['diag_1','diag_2','diag_3']]\n",
    "#for thing in diag:\n",
    "data=data.drop(['admission_type_id','discharge_disposition_id','admission_source_id','max_glu_serum','number_inpatient','number_emergency','number_outpatient','encounter_id','patient_nbr','weight','payer_code','A1Cresult','medical_specialty','max_glu_serum','diag_1','diag_2','diag_3'],axis=1)\n",
    "data=data.drop(data[data.race=='?'].index)\n",
    "\n",
    "data=data.drop(data[data.gender=='Unknown/Invalid'].index)\n",
    "#data=data.drop(data[data.diag_3==str].index)\n",
    "\n",
    "\n",
    "read=data['readmitted']\n",
    "read=read.str.upper()\n",
    "read=read.replace(['NO','<30','>30'],[0,1,1])\n",
    "\n",
    "#print(read)\n",
    "data=data.replace(['None','Female','No','Down'],0)\n",
    "data=data.replace(['Male','Yes','Up','Steady'],1)\n",
    "#data=data.replace(['[0-10)','[10-20)','[20-30)','[30-40)','[40-50)','[50-60)','[60-70)','[70-80)','[80-90)','[90-100)'],[0,1,2,3,4,5,6,7,8,9])\n",
    "data=data.replace(['Down'],2)\n",
    "#data=data.replace(['Other','Hispanic'],[3,4])\n",
    "r=pd.get_dummies(data[['race','diabetesMed']])\n",
    "change=pd.get_dummies(data['change'])\n",
    "a=pd.get_dummies(data['age'])\n",
    "#meddum=pd.get_dummies(data[meds])\n",
    "\n",
    "newdata=pd.concat([data,r,a,change],axis=1)\n",
    "newdata=newdata.drop(['age','race','readmitted','change','diabetesMed'],axis=1)\n",
    "\n",
    "X=data.drop(['readmitted'],axis=1)\n",
    "\n",
    "read=np.array(read)\n",
    "x, X_test, y, y_test = train_test_split(newdata, read, test_size = 0.15, random_state = 0)\n",
    "X_train,x_dev,y_train,y_dev=train_test_split(x,y,test_size=.18, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 100\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.558825461473\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.574196938843\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.577284372331\n",
      "100 estimators \tbest at max_depth = 15 \n",
      "score = 0.577284372331\n",
      "\n",
      "\n",
      "\n",
      "final test score: 0.574510854999\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "\n",
    "#hyperparameter grid search\n",
    "mxDepth = [5,10,15] #mxDepth \n",
    "n_ests = [100] #n_estimators \n",
    "best_models = []\n",
    "for n in n_ests:\n",
    "    print(\"n_estimators =\",n)\n",
    "    maximized_models=[]\n",
    "    for mD in mxDepth:\n",
    "        results = []\n",
    "        print(\"\\tmax_depth =\",mD)\n",
    "        for _ in range(51):\n",
    "            model = RandomForestClassifier(n_estimators=n,max_depth=mD)\n",
    "            model.fit(X_train,y_train)\n",
    "            pred = model.predict(x_dev)\n",
    "            testy=np.array(y_dev)\n",
    "            print('\\t'+str(_)+\" iterations\",end=\"\\r\",flush=True)\n",
    "\n",
    "            results.append((model,accuracy_score(pred,testy)))\n",
    "        print('\\n\\tBest model score:',max(results,key=itemgetter(1))[1])\n",
    "        maximized_models.append((max(results,key=itemgetter(1))[0],max(results,key=itemgetter(1))[1],mD))\n",
    "\n",
    "    print(n,\"estimators\",\"\\tbest at max_depth =\",max(maximized_models,key=itemgetter(1))[2],\"\\nscore =\",max(maximized_models,key=itemgetter(1))[1])\n",
    "    print(\"\\n\")\n",
    "    best_models.append((max(maximized_models,key=itemgetter(1))[0],max(maximized_models,key=itemgetter(1))[1],n))\n",
    "\n",
    "#grid search derived best model\n",
    "the_champ = max(best_models,key=itemgetter(1))[0]\n",
    "\n",
    "#score\n",
    "pred_final = the_champ.predict(X_test)\n",
    "print(\"\\nfinal test score:\",accuracy_score(pred_final,np.array(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "final test score: 0.569485392656\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
