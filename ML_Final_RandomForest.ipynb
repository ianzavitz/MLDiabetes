{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "def crossCheck(cross,foldnum):\n",
    "    scores=[]\n",
    "    for i in range(len(cross)):\n",
    "\n",
    "        ctrain=[]\n",
    "        ctrain_y=[]\n",
    "        testnum=foldnum-i-1\n",
    "        testme=[]\n",
    "        testme_y=[]\n",
    "        \n",
    "        testme=np.array(testme)\n",
    "        testme_y=np.array(testme_y)\n",
    "        j=0\n",
    "        while j<len(cross):\n",
    "\n",
    "            \n",
    "            if j!=testnum:\n",
    "                for thing in cross[j]:\n",
    "                    ctrain.append(thing[0])\n",
    "                    ctrain_y.append(thing[1])\n",
    "               \n",
    "            j+=1\n",
    "\n",
    "# meds=[]\n",
    "# with open('meds.txt') as medt:\n",
    "#     meds=medt.readline().strip().split('\\t')\n",
    "data=pd.read_csv('diabetic_data.csv')\n",
    "diag=data[['diag_1','diag_2','diag_3']]\n",
    "#for thing in diag:\n",
    "data=data.drop(['admission_type_id','discharge_disposition_id','admission_source_id','max_glu_serum','number_inpatient','number_emergency','number_outpatient','encounter_id','patient_nbr','weight','payer_code','A1Cresult','medical_specialty','max_glu_serum','diag_1','diag_2','diag_3'],axis=1)\n",
    "data=data.drop(data[data.race=='?'].index)\n",
    "\n",
    "data=data.drop(data[data.gender=='Unknown/Invalid'].index)\n",
    "#data=data.drop(data[data.diag_3==str].index)\n",
    "\n",
    "\n",
    "read=data['readmitted']\n",
    "read=read.str.upper()\n",
    "read=read.replace(['NO','<30','>30'],[0,1,1])\n",
    "\n",
    "#print(read)\n",
    "data=data.replace(['None','Female','No','Down'],0)\n",
    "data=data.replace(['Male','Yes','Up','Steady'],1)\n",
    "#data=data.replace(['[0-10)','[10-20)','[20-30)','[30-40)','[40-50)','[50-60)','[60-70)','[70-80)','[80-90)','[90-100)'],[0,1,2,3,4,5,6,7,8,9])\n",
    "data=data.replace(['Down'],2)\n",
    "#data=data.replace(['Other','Hispanic'],[3,4])\n",
    "r=pd.get_dummies(data[['race','diabetesMed']])\n",
    "change=pd.get_dummies(data['change'])\n",
    "a=pd.get_dummies(data['age'])\n",
    "#meddum=pd.get_dummies(data[meds])\n",
    "\n",
    "newdata=pd.concat([data,r,a,change],axis=1)\n",
    "newdata=newdata.drop(['age','race','readmitted','change','diabetesMed'],axis=1)\n",
    "\n",
    "X=data.drop(['readmitted'],axis=1)\n",
    "\n",
    "read=np.array(read)\n",
    "x, X_test, y, y_test = train_test_split(newdata, read, test_size = 0.15, random_state = 0)\n",
    "X_train,x_dev,y_train,y_dev=train_test_split(x,y,test_size=.18, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.563489456743\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.573277277803\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.570912435131\n",
      "10 estimators \tbest at max_depth = 10 \n",
      "score = 0.573277277803\n",
      "\n",
      "\n",
      "n_estimators = 15\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.56329238652\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.576299021218\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.570649674834\n",
      "15 estimators \tbest at max_depth = 10 \n",
      "score = 0.576299021218\n",
      "\n",
      "\n",
      "n_estimators = 20\n",
      "\tmax_depth = 5\n",
      "\t50 iterations\n",
      "\tBest model score: 0.563029626223\n",
      "\tmax_depth = 10\n",
      "\t50 iterations\n",
      "\tBest model score: 0.574985219733\n",
      "\tmax_depth = 15\n",
      "\t50 iterations\n",
      "\tBest model score: 0.572948827432\n",
      "20 estimators \tbest at max_depth = 10 \n",
      "score = 0.574985219733\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-243a7b418f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mthe_champ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mpred_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthe_champ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nfinal test score:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "\n",
    "#hyperparameter grid search\n",
    "mxDepth = [5,10,15] #mxDepth \n",
    "n_ests = [10,15,20] #n_estimators \n",
    "best_models = []\n",
    "for n in n_ests:\n",
    "    print(\"n_estimators =\",n)\n",
    "    maximized_models=[]\n",
    "    for mD in mxDepth:\n",
    "        results = []\n",
    "        print(\"\\tmax_depth =\",mD)\n",
    "        for _ in range(51):\n",
    "            model = RandomForestClassifier(n_estimators=n,max_depth=mD)\n",
    "            model.fit(X_train,y_train)\n",
    "            pred = model.predict(x_dev)\n",
    "            testy=np.array(y_dev)\n",
    "            print('\\t'+str(_)+\" iterations\",end=\"\\r\",flush=True)\n",
    "\n",
    "            results.append((model,accuracy_score(pred,testy)))\n",
    "        print('\\n\\tBest model score:',max(results,key=itemgetter(1))[1])\n",
    "        maximized_models.append((max(results,key=itemgetter(1))[0],max(results,key=itemgetter(1))[1],mD))\n",
    "\n",
    "    print(n,\"estimators\",\"\\tbest at max_depth =\",max(maximized_models,key=itemgetter(1))[2],\"\\nscore =\",max(maximized_models,key=itemgetter(1))[1])\n",
    "    print(\"\\n\")\n",
    "    best_models.append((max(maximized_models,key=itemgetter(1))[0],max(maximized_models,key=itemgetter(1))[1],n))\n",
    "\n",
    "#grid search derived best model\n",
    "the_champ = max(best_models,key=itemgetter(1))[0]\n",
    "\n",
    "#score\n",
    "pred_final = the_champ.predict(x_test)\n",
    "print(\"\\nfinal test score:\",accuracy_score(pred_final,np.array(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
